# RELAT√ìRIO FINAL - parte 2

# Introdu√ß√£o
## Prop√≥sito da an√°lise




## Estrutura do projeto e organiza√ß√£o dos arquivos
O projeto se encontra no seguinte link no Github:  https://github.com/thauanqs/DESAFIO_TELECOMX

## Instru√ß√µes para executar o notebook

Os requisitos est√£o listados em "requirements.txt" e podem ser instalados usando o comando: \
```
py -m pip install -r requirements.txt
```


# Execu√ß√£o do trabalho
A seguir se d√° como foi realizado o desenvolvimento do projeto.

## Encoding

    Transforme as vari√°veis categ√≥ricas em formato num√©rico para torn√°-las compat√≠veis com algoritmos de machine learning. Utilize um m√©todo de codifica√ß√£o adequado, como o one-hot encoding.

```
import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# Carregue o DataFrame 'dados_tratados.csv'
# Suponha que o arquivo j√° foi salvo e cont√©m as colunas limpas.
df = pd.read_csv('dados_tratados.csv')

# Identifique as colunas categ√≥ricas a serem codificadas
colunas_categoricas = [
    'Churn', 'gender', 'Partner', 'Dependents', 'PhoneService',
    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',
    'Contract', 'PaperlessBilling', 'PaymentMethod'
]

# Inicialize o OneHotEncoder
# 'sparse_output=False' garante que a sa√≠da ser√° um array denso (n√£o esparso)
ohe = OneHotEncoder(sparse_output=False)

# Aplique a codifica√ß√£o one-hot nas colunas categ√≥ricas
df_encoded_cols = ohe.fit_transform(df[colunas_categoricas])

# Crie um DataFrame com as novas colunas codificadas
# 'ohe.get_feature_names_out()' cria os nomes das colunas de forma autom√°tica
df_encoded = pd.DataFrame(df_encoded_cols, columns=ohe.get_feature_names_out(colunas_categoricas))

# Junte o novo DataFrame codificado com as colunas num√©ricas originais
# 'axis=1' garante que a concatena√ß√£o seja feita lado a lado
df_final = pd.concat([df.drop(columns=colunas_categoricas), df_encoded], axis=1)

# Verifique o resultado final do DataFrame
print(df_final.info())
print("\nPrimeiras 5 linhas do DataFrame codificado:")
print(df_final.head())
```


## Verifica√ß√£o da Propor√ß√£o de Evas√£o

    Calcule a propor√ß√£o de clientes que evadiram em rela√ß√£o aos que permaneceram ativos. Avalie se h√° desequil√≠brio entre as classes, o que pode impactar modelos preditivos e a an√°lise de resultados.


Execu√ß√£o:
```
import pandas as pd

# Carregue o DataFrame final que foi salvo ap√≥s a codifica√ß√£o
df = pd.read_csv('df_final.csv')

# Calcule a contagem de cada classe na coluna 'Churn_Yes'
# 1 = Clientes que evadiram (Yes)
# 0 = Clientes que permaneceram (No)
contagem_classes = df['Churn_Yes'].value_counts()

# Calcule a propor√ß√£o de cada classe em porcentagem
proporcao_classes = df['Churn_Yes'].value_counts(normalize=True) * 100

print("Contagem de clientes por classe:")
print(contagem_classes)
print("\nPropor√ß√£o de clientes por classe (%):")
print(proporcao_classes)

# Salvar a contagem e a propor√ß√£o para refer√™ncia futura (opcional)
contagem_classes.to_csv('contagem_classes.csv')
proporcao_classes.to_csv('proporcao_classes.csv')

```
Obtemos o retorno:
```
Contagem de clientes por classe:
Churn_Yes
0.0    5009
1.0    1821
Name: count, dtype: int64

Propor√ß√£o de clientes por classe (%):
Churn_Yes
0.0    73.338214
1.0    26.661786
Name: proportion, dtype: float64

```
## Correla√ß√£o e sele√ß√£o de vari√°veis

    Visualize a matriz de correla√ß√£o para identificar rela√ß√µes entre vari√°veis num√©ricas. Observe especialmente quais vari√°veis apresentam maior correla√ß√£o com a evas√£o, pois elas podem ser fortes candidatas para o modelo preditivo.


Execu√ß√£o:
```

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregue o DataFrame final que cont√©m as vari√°veis num√©ricas
df = pd.read_csv('df_final.csv')

# Calcule a matriz de correla√ß√£o do DataFrame
correlation_matrix = df.corr()

# Configure o estilo e o tamanho do gr√°fico
plt.style.use('ggplot')
plt.figure(figsize=(20, 15))

# Crie o mapa de calor (heatmap)
sns.heatmap(
    correlation_matrix,
    annot=True,        # Mostra os valores de correla√ß√£o no mapa
    cmap='coolwarm',   # Define o esquema de cores
    fmt=".2f",         # Formata os valores com 2 casas decimais
    linewidths=.5,     # Adiciona linhas entre as c√©lulas
    vmin=-1,           # Garante que a escala de cor v√° de -1 a 1
    vmax=1
)

# Adicione um t√≠tulo ao gr√°fico
plt.title('Matriz de Correla√ß√£o das Vari√°veis', fontsize=20)

# Rotacione os r√≥tulos do eixo x para melhor visualiza√ß√£o
plt.xticks(rotation=90)
plt.yticks(rotation=0)

# Garanta que o layout da figura se ajuste bem
plt.tight_layout()

# Exiba o gr√°fico
plt.show()

# Opcionalmente, salve a figura em um arquivo
# plt.savefig('matriz_de_correlacao.png')

```
Resultados:
![alt text](image.png)


## An√°lises Direcionadas

    Investigue como vari√°veis espec√≠ficas se relacionam com a evas√£o, como:
    Tempo de contrato √ó Evas√£o
    Total gasto √ó Evas√£o
    Utilize gr√°ficos como boxplots ou dispers√£o (scatter plots) para visualizar padr√µes e poss√≠veis tend√™ncias.



Execu√ß√£o:
```
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregue o DataFrame final com as vari√°veis num√©ricas e codificadas
df = pd.read_csv('df_final.csv')

# Configure o estilo dos gr√°ficos
sns.set_style('whitegrid')

# -----------------
# 1. Boxplots: Tempo de Contrato (tenure) e Total Gasto (Charges.Total) vs. Evas√£o (Churn_Yes)
# -----------------

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Boxplot para Tempo de Contrato (tenure) vs. Churn
sns.boxplot(x='Churn_Yes', y='tenure', data=df, ax=axes[0])
axes[0].set_title('Tempo de Contrato (Anos) por Evas√£o', fontsize=14)
axes[0].set_xlabel('Evas√£o (0: N√£o, 1: Sim)', fontsize=12)
axes[0].set_ylabel('Anos de Contrato', fontsize=12)

# Boxplot para Total Gasto (Charges.Total) vs. Churn
sns.boxplot(x='Churn_Yes', y='Charges.Total', data=df, ax=axes[1])
axes[1].set_title('Total Gasto por Evas√£o', fontsize=14)
axes[1].set_xlabel('Evas√£o (0: N√£o, 1: Sim)', fontsize=12)
axes[1].set_ylabel('Total Gasto ($)', fontsize=12)

plt.tight_layout()
plt.show()


# -----------------
# 2. Scatter Plot: Tempo de Contrato vs. Total Gasto, colorido por Evas√£o
# -----------------

plt.figure(figsize=(10, 8))
sns.scatterplot(
    x='tenure',
    y='Charges.Total',
    hue='Churn_Yes',  # Cor por status de evas√£o
    data=df,
    palette='viridis',
    s=50,             # Tamanho dos pontos
    alpha=0.6         # Transpar√™ncia
)

plt.title('Dispers√£o entre Tempo de Contrato e Total Gasto por Evas√£o', fontsize=14)
plt.xlabel('Tempo de Contrato (Anos)', fontsize=12)
plt.ylabel('Total Gasto ($)', fontsize=12)
plt.legend(title='Evas√£o', labels=['N√£o Evadiu', 'Evadiu'])
plt.show()

```
Resultado:


![alt text](image-1.png)
![alt text](image-2.png)


## Separa√ß√£o de Dados

    Divida o conjunto de dados em treino e teste para avaliar o desempenho do modelo. Uma divis√£o comum √© 70% para treino e 30% para teste, ou 80/20, dependendo do tamanho da base de dados.



Execu√ß√£o:
```
import pandas as pd
from sklearn.model_selection import train_test_split

# Carregue o DataFrame final que cont√©m todas as vari√°veis prontas para o modelo
df = pd.read_csv('df_final.csv')

# Defina a vari√°vel alvo (target) e as vari√°veis preditoras (features)
# A coluna 'Churn_Yes' √© a nossa vari√°vel alvo
y = df['Churn_Yes']

# As vari√°veis preditoras s√£o todas as outras colunas
X = df.drop('Churn_Yes', axis=1)

# Divida os dados em treino e teste
# test_size=0.3 indica que 30% dos dados ser√£o usados para teste
# random_state=42 garante que a divis√£o seja a mesma a cada execu√ß√£o, para reprodutibilidade
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Opcional: Para lidar com o desequil√≠brio de classes, use o argumento 'stratify'
# Isso garante que a propor√ß√£o das classes (evas√£o/n√£o evas√£o) seja a mesma nos conjuntos de treino e teste
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.3, random_state=42, stratify=y
# )

# Imprima as dimens√µes dos novos conjuntos de dados para verificar o sucesso da divis√£o
print(f"Dimens√µes do conjunto de treino (X_train): {X_train.shape}")
print(f"Dimens√µes do conjunto de teste (X_test): {X_test.shape}")
print(f"Dimens√µes da vari√°vel alvo de treino (y_train): {y_train.shape}")
print(f"Dimens√µes da vari√°vel alvo de teste (y_test): {y_test.shape}")


```
Resultado:

```
Dimens√µes do conjunto de treino (X_train): (4781, 48)
Dimens√µes do conjunto de teste (X_test): (2049, 48)
Dimens√µes da vari√°vel alvo de treino (y_train): (4781,)
Dimens√µes da vari√°vel alvo de teste (y_test): (2049,)

```


## Cria√ß√£o de Modelos

    Crie pelo menos dois modelos diferentes para prever a evas√£o de clientes.

    Um modelo pode exigir normaliza√ß√£o, como Regress√£o Log√≠stica ou KNN.

    O outro modelo pode n√£o exigir normaliza√ß√£o, como √Årvore de Decis√£o ou Random Forest.

    üí° A escolha de aplicar ou n√£o a normaliza√ß√£o depende dos modelos selecionados. Ambos os modelos podem ser criados sem normaliza√ß√£o, mas a combina√ß√£o de modelos com e sem normaliza√ß√£o tamb√©m √© uma op√ß√£o.

    Justifique a escolha de cada modelo e, se optar por normalizar os dados, explique a necessidade dessa etapa.






Execu√ß√£o:
```
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Carregue o DataFrame final
df = pd.read_csv('df_final.csv')

# --- PASSO CORRIGIDO ---
# Remova todas as linhas que contenham valores nulos
# O erro indica que Charges.Total ainda tem valores NaN
df.dropna(inplace=True)
# ----------------------

# Defina a vari√°vel alvo (y) e as preditoras (X)
y = df['Churn_Yes']
X = df.drop('Churn_Yes', axis=1)

# Divida os dados em treino e teste, mantendo a propor√ß√£o de classes
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# -----------------------------------------------------------
# Modelo 1: Regress√£o Log√≠stica com Normaliza√ß√£o
# -----------------------------------------------------------

print("Treinando o modelo de Regress√£o Log√≠stica...")

# Inicialize o StandardScaler
scaler = StandardScaler()

# Ajuste o scaler aos dados de treino e normalize os conjuntos de treino e teste
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Crie e treine o modelo de Regress√£o Log√≠stica
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train_scaled, y_train)

print("Modelo de Regress√£o Log√≠stica treinado com sucesso!")
print("-" * 50)


# -----------------------------------------------------------
# Modelo 2: Random Forest sem Normaliza√ß√£o
# -----------------------------------------------------------

print("Treinando o modelo Random Forest...")

# Crie e treine o modelo Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

print("Modelo Random Forest treinado com sucesso!")
print("-" * 50)


```
Resultado:
```
Treinando o modelo de Regress√£o Log√≠stica...
Modelo de Regress√£o Log√≠stica treinado com sucesso!
--------------------------------------------------
Treinando o modelo Random Forest...
Modelo Random Forest treinado com sucesso!
--------------------------------------------------

```

## Avalia√ß√£o dos Modelos
    Avalie cada modelo utilizando as seguintes m√©tricas:
    Acur√°cia
    Precis√£o
    Recall
    F1-score
    Matriz de confus√£o
    Em seguida, fa√ßa uma an√°lise cr√≠tica e compare os modelos:
    Qual modelo teve o melhor desempenho?
    Algum modelo apresentou overfitting ou underfitting? Se sim, considere as poss√≠veis causas e ajustes:
    Overfitting: Quando o modelo aprende demais sobre os dados de treino, perdendo a capacidade de generalizar para novos dados. Considere reduzir a complexidade do modelo ou aumentar os dados de treino.
    Underfitting: Quando o modelo n√£o captura bem as tend√™ncias dos dados, indicando que est√° muito simples. Tente aumentar a complexidade do modelo ou ajustar seus par√¢metros.




Execu√ß√£o:
```
import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------------------------------------
# Avalia√ß√£o do Modelo 1: Regress√£o Log√≠stica
# -----------------------------------------------------------
print("=== Avalia√ß√£o do Modelo de Regress√£o Log√≠stica ===")

# Fa√ßa previs√µes no conjunto de teste escalado
y_pred_lr = log_reg.predict(X_test_scaled)
y_pred_proba_lr = log_reg.predict_proba(X_test_scaled)[:, 1]

# Calcule e imprima as m√©tricas
print(f"Acur√°cia: {accuracy_score(y_test, y_pred_lr):.4f}")
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred_lr))

# Matriz de Confus√£o
print("Matriz de Confus√£o:")
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Matriz de Confus√£o - Regress√£o Log√≠stica')
plt.xlabel('Previs√£o')
plt.ylabel('Real')
plt.show()

# -----------------------------------------------------------
# Avalia√ß√£o do Modelo 2: Random Forest
# -----------------------------------------------------------
print("\n\n=== Avalia√ß√£o do Modelo Random Forest ===")

# Fa√ßa previs√µes no conjunto de teste original (n√£o escalado)
y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Calcule e imprima as m√©tricas
print(f"Acur√°cia: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred_rf))

# Matriz de Confus√£o
print("Matriz de Confus√£o:")
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Matriz de Confus√£o - Random Forest')
plt.xlabel('Previs√£o')
plt.ylabel('Real')
plt.show()


```
Resultado:
```
=== Avalia√ß√£o do Modelo de Regress√£o Log√≠stica ===
Acur√°cia: 1.0000

Relat√≥rio de Classifica√ß√£o:
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00      1501
         1.0       1.00      1.00      1.00       545

    accuracy                           1.00      2046
   macro avg       1.00      1.00      1.00      2046
weighted avg       1.00      1.00      1.00      2046

Matriz de Confus√£o:

```
![alt text](image-3.png)


```
=== Avalia√ß√£o do Modelo Random Forest ===
Acur√°cia: 1.0000

Relat√≥rio de Classifica√ß√£o:
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00      1501
         1.0       1.00      1.00      1.00       545

    accuracy                           1.00      2046
   macro avg       1.00      1.00      1.00      2046
weighted avg       1.00      1.00      1.00      2046

Matriz de Confus√£o:

```
![alt text](image-4.png)